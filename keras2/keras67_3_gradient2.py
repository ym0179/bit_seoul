#Day18
#2020-11-18

import numpy as np
import matplotlib.pyplot as plt

f = lambda x: x**2 -4*x + 6 #2차 함수

gradient = lambda x: 2*x - 4 #f 함수의 미분
# 미분값 0인 지점 = 2차함수의 최저점
# x가 2인 지점을 찾아야함

x0 = 0.0
MaxIter = 30
learning_Rate = 0.25

print("step\tx\tf(x)")
print("{:02d}\t{:6.5f}\t{:6.5f}".format(0,x0,f(x0)))
print("==========================================")
for i in range(MaxIter):
    x1 = x0 - learning_Rate * gradient(x0)
    x0 = x1

    print("{:02d}\t{:6.5f}\t{:6.5f}".format(i+1,x0,f(x0)))

'''
lr = 0.25
step    x       f(x)
00      0.00000 6.00000
========================
01      1.00000 3.00000
02      1.50000 2.25000
03      1.75000 2.06250
04      1.87500 2.01562
05      1.93750 2.00391
06      1.96875 2.00098
07      1.98438 2.00024
08      1.99219 2.00006
09      1.99609 2.00002
10      1.99805 2.00000 #10 번만에 f(x) 최저점 찾음

lr = 0.1
step    x       f(x)
00      0.00000 6.00000
==========================================
01      0.40000 4.56000
02      0.72000 3.63840
03      0.97600 3.04858
04      1.18080 2.67109
05      1.34464 2.42950
06      1.47571 2.27488
07      1.58057 2.17592
08      1.66446 2.11259
09      1.73156 2.07206
10      1.78525 2.04612
11      1.82820 2.02951
12      1.86256 2.01889
13      1.89005 2.01209
14      1.91204 2.00774
15      1.92963 2.00495
16      1.94371 2.00317
17      1.95496 2.00203
18      1.96397 2.00130
19      1.97118 2.00083
20      1.97694 2.00053
21      1.98155 2.00034
22      1.98524 2.00022
23      1.98819 2.00014
24      1.99056 2.00009
25      1.99244 2.00006
26      1.99396 2.00004
27      1.99516 2.00002
28      1.99613 2.00001
29      1.99691 2.00001
30      1.99752 2.00001
'''
